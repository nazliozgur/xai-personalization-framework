{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ“Š XAE-Frame: Exploratory Data Analysis (EDA)\n",
    "## Amazon Reviews 2023 - All_Beauty Category\n",
    "\n",
    "**Author:** NazlÄ± Ã–zgÃ¼r  \n",
    "**Date:** December 2024  \n",
    "**Dataset:** Amazon Reviews 2023 (McAuley Lab)\n",
    "\n",
    "---\n",
    "\n",
    "## Objectives\n",
    "1. Understand data structure and quality\n",
    "2. Identify patterns for recommendation system\n",
    "3. Detect potential bias sources for fairness monitoring\n",
    "4. Prepare publication-quality visualizations\n",
    "5. Inform feature engineering decisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for publication-quality plots\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 11\n",
    "plt.rcParams['axes.labelsize'] = 12\n",
    "plt.rcParams['axes.titlesize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 10\n",
    "plt.rcParams['ytick.labelsize'] = 10\n",
    "plt.rcParams['legend.fontsize'] = 10\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data_path = Path(\"../data/raw/amazon_reviews_All_Beauty.parquet\")\n",
    "\n",
    "if not data_path.exists():\n",
    "    print(f\"Data file not found: {data_path}\")\n",
    "    print(\"Please run: python scripts/download_data.py --dataset amazon_reviews --category All_Beauty\")\n",
    "else:\n",
    "    df = pd.read_parquet(data_path)\n",
    "    print(f\"  Data loaded successfully!\")\n",
    "    print(f\"  Shape: {df.shape[0]:,} rows Ã— {df.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data info\n",
    "print(\"Dataset Information:\")\n",
    "print(\"=\" * 50)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Data Quality Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values analysis\n",
    "missing = df.isnull().sum()\n",
    "missing_pct = (missing / len(df)) * 100\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Count': missing,\n",
    "    'Missing %': missing_pct\n",
    "}).sort_values('Missing %', ascending=False)\n",
    "\n",
    "print(\"Missing Values Analysis:\")\n",
    "print(\"=\" * 50)\n",
    "print(missing_df[missing_df['Missing Count'] > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize missing data (Publication-quality)\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "missing_plot = missing_df[missing_df['Missing Count'] > 0].sort_values('Missing %')\n",
    "if len(missing_plot) > 0:\n",
    "    missing_plot['Missing %'].plot(kind='barh', ax=ax, color='coral')\n",
    "    ax.set_xlabel('Missing Data (%)', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('Features', fontsize=12, fontweight='bold')\n",
    "    ax.set_title('Missing Data Analysis - Amazon Beauty Reviews', \n",
    "                 fontsize=14, fontweight='bold', pad=20)\n",
    "    ax.grid(axis='x', alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../docs/figures/missing_data.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No missing data found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics\n",
    "print(\"\\nBasic Statistics:\")\n",
    "print(\"=\" * 50)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Rating Distribution Analysis\n",
    "\n",
    "**Key for recommendation systems:** Understanding rating patterns helps design appropriate loss functions and identify potential biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rating distribution\n",
    "rating_counts = df['rating'].value_counts().sort_index()\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Bar plot\n",
    "rating_counts.plot(kind='bar', ax=axes[0], color='steelblue', edgecolor='black')\n",
    "axes[0].set_xlabel('Rating', fontsize=12, fontweight='bold')\n",
    "axes[0].set_ylabel('Frequency', fontsize=12, fontweight='bold')\n",
    "axes[0].set_title('Rating Distribution', fontsize=14, fontweight='bold')\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Percentage pie chart\n",
    "rating_pct = (rating_counts / rating_counts.sum()) * 100\n",
    "colors = sns.color_palette('Set2', len(rating_pct))\n",
    "axes[1].pie(rating_pct, labels=rating_pct.index, autopct='%1.1f%%', \n",
    "            startangle=90, colors=colors)\n",
    "axes[1].set_title('Rating Distribution (%)', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../docs/figures/rating_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nRating Statistics:\")\n",
    "print(f\"  Mean Rating: {df['rating'].mean():.2f}\")\n",
    "print(f\"  Median Rating: {df['rating'].median():.2f}\")\n",
    "print(f\"  Std Dev: {df['rating'].std():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Temporal Analysis\n",
    "\n",
    "**Critical for drift detection:** Understanding temporal patterns helps identify when to trigger model retraining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert timestamp to datetime if needed\n",
    "if 'timestamp' in df.columns:\n",
    "    df['date'] = pd.to_datetime(df['timestamp'], unit='ms', errors='coerce')\n",
    "    df['year'] = df['date'].dt.year\n",
    "    df['month'] = df['date'].dt.month\n",
    "    df['year_month'] = df['date'].dt.to_period('M')\n",
    "    \n",
    "    # Reviews over time\n",
    "    reviews_over_time = df.groupby('year_month').size()\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(14, 6))\n",
    "    reviews_over_time.plot(ax=ax, color='darkblue', linewidth=2)\n",
    "    ax.set_xlabel('Time Period', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('Number of Reviews', fontsize=12, fontweight='bold')\n",
    "    ax.set_title('Review Volume Over Time', fontsize=14, fontweight='bold', pad=20)\n",
    "    ax.grid(alpha=0.3)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../docs/figures/temporal_analysis.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nTemporal Coverage:\")\n",
    "    print(f\"  First Review: {df['date'].min()}\")\n",
    "    print(f\"  Last Review: {df['date'].max()}\")\n",
    "    print(f\"  Time Span: {(df['date'].max() - df['date'].min()).days} days\")\n",
    "else:\n",
    "    print(\"No timestamp column found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. User and Item Analysis\n",
    "\n",
    "**Essential for collaborative filtering:** Identifying power users and popular items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User activity analysis\n",
    "user_id_col = 'user_id' if 'user_id' in df.columns else 'reviewerID'\n",
    "item_id_col = 'parent_asin' if 'parent_asin' in df.columns else 'asin'\n",
    "\n",
    "user_activity = df.groupby(user_id_col).size().reset_index(name='review_count')\n",
    "item_popularity = df.groupby(item_id_col).size().reset_index(name='review_count')\n",
    "\n",
    "print(\"User Activity Statistics:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"  Total Unique Users: {df[user_id_col].nunique():,}\")\n",
    "print(f\"  Avg Reviews per User: {user_activity['review_count'].mean():.2f}\")\n",
    "print(f\"  Median Reviews per User: {user_activity['review_count'].median():.0f}\")\n",
    "print(f\"  Max Reviews by Single User: {user_activity['review_count'].max():,}\")\n",
    "\n",
    "print(\"\\nItem Popularity Statistics:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"  Total Unique Items: {df[item_id_col].nunique():,}\")\n",
    "print(f\"  Avg Reviews per Item: {item_popularity['review_count'].mean():.2f}\")\n",
    "print(f\"  Median Reviews per Item: {item_popularity['review_count'].median():.0f}\")\n",
    "print(f\"  Max Reviews for Single Item: {item_popularity['review_count'].max():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize user and item distributions\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# User distribution (log scale for better visibility)\n",
    "axes[0].hist(user_activity['review_count'], bins=50, color='teal', edgecolor='black', alpha=0.7)\n",
    "axes[0].set_xlabel('Number of Reviews per User', fontsize=12, fontweight='bold')\n",
    "axes[0].set_ylabel('Frequency (log scale)', fontsize=12, fontweight='bold')\n",
    "axes[0].set_title('User Activity Distribution', fontsize=14, fontweight='bold')\n",
    "axes[0].set_yscale('log')\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Item distribution (log scale)\n",
    "axes[1].hist(item_popularity['review_count'], bins=50, color='coral', edgecolor='black', alpha=0.7)\n",
    "axes[1].set_xlabel('Number of Reviews per Item', fontsize=12, fontweight='bold')\n",
    "axes[1].set_ylabel('Frequency (log scale)', fontsize=12, fontweight='bold')\n",
    "axes[1].set_title('Item Popularity Distribution', fontsize=14, fontweight='bold')\n",
    "axes[1].set_yscale('log')\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../docs/figures/user_item_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Sparsity Analysis\n",
    "\n",
    "**Critical metric for recommendation systems:** High sparsity = cold start challenge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate sparsity\n",
    "n_users = df[user_id_col].nunique()\n",
    "n_items = df[item_id_col].nunique()\n",
    "n_ratings = len(df)\n",
    "\n",
    "sparsity = 1 - (n_ratings / (n_users * n_items))\n",
    "\n",
    "print(\"\\nData Sparsity Analysis:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"  Total Possible Interactions: {n_users * n_items:,}\")\n",
    "print(f\"  Actual Interactions: {n_ratings:,}\")\n",
    "print(f\"  Sparsity: {sparsity * 100:.4f}%\")\n",
    "print(f\"  Density: {(1 - sparsity) * 100:.4f}%\")\n",
    "print(\"\\n Insight: High sparsity indicates need for:\")\n",
    "print(\"   - Cross-domain transfer learning\")\n",
    "print(\"   - Hybrid recommendation approaches\")\n",
    "print(\"   - Content-based features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Text Analysis (Review Text)\n",
    "\n",
    "**For content-based features and sentiment analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if review text exists\n",
    "if 'text' in df.columns:\n",
    "    # Remove null values\n",
    "    df_text = df[df['text'].notna()].copy()\n",
    "    \n",
    "    # Calculate text length\n",
    "    df_text['text_length'] = df_text['text'].str.len()\n",
    "    df_text['word_count'] = df_text['text'].str.split().str.len()\n",
    "    \n",
    "    print(\"\\nReview Text Statistics:\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"  Reviews with Text: {len(df_text):,} ({len(df_text)/len(df)*100:.1f}%)\")\n",
    "    print(f\"  Avg Characters: {df_text['text_length'].mean():.0f}\")\n",
    "    print(f\"  Avg Words: {df_text['word_count'].mean():.0f}\")\n",
    "    print(f\"  Median Words: {df_text['word_count'].median():.0f}\")\n",
    "    \n",
    "    # Visualize text length distribution\n",
    "    fig, ax = plt.subplots(figsize=(12, 5))\n",
    "    ax.hist(df_text['word_count'], bins=50, color='purple', edgecolor='black', alpha=0.7)\n",
    "    ax.set_xlabel('Number of Words', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('Frequency', fontsize=12, fontweight='bold')\n",
    "    ax.set_title('Review Text Length Distribution', fontsize=14, fontweight='bold')\n",
    "    ax.axvline(df_text['word_count'].mean(), color='red', linestyle='--', \n",
    "               linewidth=2, label=f\"Mean: {df_text['word_count'].mean():.0f}\")\n",
    "    ax.legend()\n",
    "    ax.grid(alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../docs/figures/text_length_distribution.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\" No review text column found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Verified Purchase Analysis\n",
    "\n",
    "**For trust and quality signals**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'verified_purchase' in df.columns:\n",
    "    verified_counts = df['verified_purchase'].value_counts()\n",
    "    \n",
    "    print(\"\\nVerified Purchase Analysis:\")\n",
    "    print(\"=\" * 50)\n",
    "    print(verified_counts)\n",
    "    print(f\"\\nVerified Purchase Rate: {verified_counts.get(True, 0) / len(df) * 100:.1f}%\")\n",
    "    \n",
    "    # Compare ratings: verified vs non-verified\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    df.boxplot(column='rating', by='verified_purchase', ax=ax)\n",
    "    ax.set_xlabel('Verified Purchase', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('Rating', fontsize=12, fontweight='bold')\n",
    "    ax.set_title('Rating Distribution: Verified vs Non-Verified', \n",
    "                 fontsize=14, fontweight='bold')\n",
    "    plt.suptitle('')  # Remove default title\n",
    "    ax.grid(alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../docs/figures/verified_purchase_analysis.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\" No verified_purchase column found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. Data Quality Summary & Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"DATA QUALITY SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\n Strengths:\")\n",
    "print(f\"  â€¢ Dataset Size: {len(df):,} reviews (sufficient for deep learning)\")\n",
    "print(f\"  â€¢ User Coverage: {df[user_id_col].nunique():,} unique users\")\n",
    "print(f\"  â€¢ Item Coverage: {df[item_id_col].nunique():,} unique products\")\n",
    "print(f\"  â€¢ Temporal Range: {(df['date'].max() - df['date'].min()).days if 'date' in df.columns else 'N/A'} days\")\n",
    "\n",
    "print(\"\\n Challenges:\")\n",
    "print(f\"  â€¢ Sparsity: {sparsity * 100:.2f}% (requires transfer learning)\")\n",
    "print(f\"  â€¢ Rating Bias: {(df['rating'] >= 4).sum() / len(df) * 100:.1f}% positive ratings\")\n",
    "if 'text' in df.columns:\n",
    "    print(f\"  â€¢ Text Coverage: {df['text'].notna().sum() / len(df) * 100:.1f}% have review text\")\n",
    "\n",
    "print(\"\\n Recommendations for XAE-Frame:\")\n",
    "print(\"  1. Cross-domain transfer: Leverage this dataset to improve cold-start in other domains\")\n",
    "print(\"  2. Hybrid approach: Combine collaborative + content-based (text) features\")\n",
    "print(\"  3. Temporal modeling: Use timestamps for drift detection triggers\")\n",
    "print(\"  4. Fairness monitoring: Check for bias across user segments (if demographic data available)\")\n",
    "print(\"  5. Text mining: Extract product attributes from reviews for explainability\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 10. Save Processed Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary statistics dictionary\n",
    "summary_stats = {\n",
    "    'dataset_size': len(df),\n",
    "    'n_users': n_users,\n",
    "    'n_items': n_items,\n",
    "    'sparsity': sparsity,\n",
    "    'avg_rating': df['rating'].mean(),\n",
    "    'rating_std': df['rating'].std(),\n",
    "    'date_range_days': (df['date'].max() - df['date'].min()).days if 'date' in df.columns else None,\n",
    "    'avg_reviews_per_user': user_activity['review_count'].mean(),\n",
    "    'avg_reviews_per_item': item_popularity['review_count'].mean(),\n",
    "}\n",
    "\n",
    "# Save to JSON\n",
    "import json\n",
    "with open('../data/processed/eda_summary.json', 'w') as f:\n",
    "    json.dump(summary_stats, f, indent=2, default=str)\n",
    "\n",
    "print(\"\\n Summary statistics saved to: data/processed/eda_summary.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Next Steps\n",
    "\n",
    "Following this exploratory analysis, the subsequent phases of the XAE-Frame development include:\n",
    "\n",
    "1. **Feature Engineering** - Creating explainable, domain-transferable features from raw data\n",
    "2. **Baseline Model Training** - Implementing LightGBM/XGBoost recommendation models\n",
    "3. **Explainability Integration** - SHAP value computation and multi-level explanation generation\n",
    "4. **Adaptive Learning** - Drift detection and automated retraining mechanisms\n",
    "5. **Fairness Monitoring** - Bias detection across user segments and demographic groups\n",
    "6. **Cross-Domain Transfer** - Extending the framework to finance and insurance domains\n",
    "\n",
    "---\n",
    "\n",
    "**Note:** All visualizations are generated at 300 DPI resolution and saved in `docs/figures/` for use in academic publications and professional presentations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
